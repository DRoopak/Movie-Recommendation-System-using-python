# -*- coding: utf-8 -*-
"""Movie Recommendation System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DB2fkjp44DLeM7jugu0xxijg5JP8xZdm
"""

import numpy as np

import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

credits_df = pd.read_csv("credits.csv", low_memory=False)
movies_df = pd.read_csv("movies.csv", low_memory=False)

credits_df = pd.read_csv("credits.csv")
  movies_df = pd.read_csv("movies.csv")

credits_df

movies_df

pd.set_option('display.max_columns',None)
pd.set_option('display.max_rows',None)

credits_df

movies_df

credits_df.head()

movies_df.tail()

movies_df = movies_df.merge(credits_df, on='title')

movies_df.shape

movies_df.head()

movies_df.info()

movies_df = movies_df[['movie_id','title','overview','genres','keywords','cast','crew']]

movies_df.head()

movies_df.info()

#how many missing values are present
movies_df.isnull().sum()

movies_df.dropna(inplace=True)

# Check the data types of each column
movies_df.dtypes

movies_df = movies_df[~movies_df['cast'].apply(lambda x: isinstance(x, list))]

movies_df

movies_df['cast'] = movies_df['cast'].apply(lambda x: ','.join(x))

movies_df

#it shows duplicated values
movies_df.duplicated().sum()

movies_df.iloc[0].genres
#it shows the 0 line poision

import ast
#import is a class defines is a ast module tht is expressed statement in python in the form of abstract syntax tree

def convert(obj):
  L=[]
  for i in ast.literal_eval(obj):
    L.append(i['name'])
    return L

movies_df['genres'] = movies_df['genres'].apply(convert)
movies_df['keywords'] = movies_df['keywords'].apply(convert)
movies_df.head()

def convert(obj):
  L=[]
  counter = 0
  for i in ast.literal_eval(obj):
    if counter !=3:
      L.append(i['name'])
      counter +=1
    else:
        break
        return L

['In', 'the', '22nd', 'century,', 'a', 'paraplegic', 'Marine', 'is', 'dispatched', 'to', 'the', 'moon', 'Pandora', 'on', 'a', 'unique', 'mission,', 'but', 'becomes', 'torn', 'between', 'following', 'orders', 'and', 'protecting', 'an', 'alien', 'civilization.']

import json

def convert(obj):
    try:
        return json.loads(obj)
    except json.JSONDecodeError:
        return []

movies_df['overview'] = movies_df['overview'].apply(convert)

movies_df.head()

def fetch_director(obj):
  L=[]
  for i in ast.literal_eval(obj):
    if i['job']=='Director':
      L.append(i['name'])
      break
  return L
      #fetch_director is a function name

movies_df = pd.read_csv("movies.csv")

movies_df['overview'][0]

movies_df['overview'].dtype

import pandas as pd

def split_strings(value):
  """
  Checks if the value is a string and splits it if it is.
  """
  if isinstance(value, str):
    return value.split()
  else:
    return value

movies_df = pd.read_csv("movies.csv")
movies_df['overview'] = movies_df['overview'].apply(split_strings)
print(movies_df['overview'])

movies_df['genres']=movies_df['genres'].apply(lambda x:[i.replace("","")for i in x])

movies_df

movies_df['keywords']=movies_df['keywords'].apply(lambda x:[i.replace("","")for i in x])

movies_df

movies_df['tags']=movies_df['overview']+movies_df['genres']+movies_df['keywords']

movies_df

if 'movie_id' in movies_df.columns:
    new_df = movies_df[['movie_id', 'title', 'tags']]
else:
    print("Column 'movie_id' does not exist in the DataFrame.")

movies_df.rename(columns={'id': 'movie_id'}, inplace=True)
new_df = movies_df[['movie_id', 'title', 'tags']]

new_df

new_df['tags'][0]

new_df['tags'].dtype

new_df.head()

new_df = new_df[~new_df['tags'].isna()]
new_df

new_df['tags'] = new_df['tags'].fillna('')
new_df

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features= 5000, stop_words='english')

# Remove rows containing np.nan values from the 'tags' column
new_df = new_df[~new_df['tags'].isna()]

# Fit the CountVectorizer on the 'tags' column
cv.fit_transform(new_df['tags']).toarray().shape

def nested_list_analyzer(doc):
  """
  Analyzes a nested list of strings and returns a list of tokens.
  """
  tokens = []
  for sublist in doc:
    for item in sublist:
      tokens.append(item)
  return tokens

cv = CountVectorizer(max_features=5000, stop_words='english', analyzer=nested_list_analyzer)
X = cv.fit_transform(new_df['tags']).toarray()

new_df['tags'] = new_df['tags'].apply(lambda x: ' '.join(x))
cv.fit_transform(new_df['tags']).toarray().shape

cv.fit_transform(new_df['tags']).toarray().shape

vectors = cv.fit_transform(new_df['tags']).toarray()

vectors[0]

import nltk

from nltk.stem.porter import PorterStemmer
ps = PorterStemmer()

def stem(text):
  y=[]
  for i in text.split():
      y.append(ps.stem(i))
  return " ".join(y)

new_df['tags']= new_df['tags'].apply(stem)

from sklearn.metrics.pairwise import cosine_similarity

cosine_similarity(vectors)

cosine_similarity(vectors).shape

similarity = cosine_similarity(vectors)

similarity[0]

similarity[0].shape

sorted(list(enumerate(similarity[0])),reverse= True, key=lambda x:x[1])[1:6]

def recommend(movie):
    movie_index=new_df[new_df['title']==movie].index[0]
    distances=similarity[movie_index]
    movies_list=sorted(list(enumerate(distances)),reverse=True,key=lambda x:x[1])[1:6]

    for i in movies_list:
        print(new_df.iloc[i[0]].title)

recommend('Avatar')

recommend('Iron Man')

recommend('Liar Liar')

recommend('Captain America: Civil War')

